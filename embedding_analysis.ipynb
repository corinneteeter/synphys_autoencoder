{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Characterize how well embeddings resolve different features.  \n",
    "This file assumes that there are standardized features supplied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.io as sio\n",
    "sns.set()\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier,  AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import metrics\n",
    "import plotly\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "# Configure Plotly to be rendered inline in the notebook.\n",
    "plotly.offline.init_notebook_mode()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading files from allen file system mat directory\n",
    "# mount_point    = '/Users/fruity/Remote-AI-root/allen/aibs' #Rohan's mount point\n",
    "# mount_point    = '/allen/aibs' #Corinne's mount point\n",
    "# data_dir       = mount_point + 'mat/Corinne/autoencoder/'\n",
    "#embeddings_dir = mount_point+'mat/Corinne/autoencoder/embeddings/'\n",
    "\n",
    "#Load Corinne's data file:\n",
    "#dat_df=pd.read_csv(data_dir+'ae_data_50hz_sequential_10_24_2019.csv', sep='#',low_memory=False)\n",
    "\n",
    "#Load embeddings:\n",
    "#mat = sio.loadmat(embeddings_dir+'TEST_cv_0_pd_0-2_bs_1000_ld_2_ne_10000_ri_0-summary.mat, \\\n",
    "#                  squeeze_me=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading files locally\n",
    "# sequential data\n",
    "df=pd.read_csv('data2_first_8_pulses/ae_data_50hz_sequential_10_24_2019UPDATE.csv', sep='#',low_memory=False)\n",
    "embed2D = sio.loadmat('data2_first_8_pulses/TEST_cv_0_pd_0-2_bs_1000_ld_2_ne_10000_ri_0-summary.mat', squeeze_me=True)\n",
    "embed3D = sio.loadmat('data2_first_8_pulses/TEST-3D_cv_0_pd_0-2_bs_1000_ld_3_ne_10000_ri_0-summary.mat', squeeze_me=True)\n",
    "\n",
    "# random data\n",
    "# This doesnt yet work due to the key stadarization of the mat file and no 3d embedding\n",
    "# df=pd.read_csv('data1_random/ae_data_09_06_2019UPDATE.csv', sep='#',low_memory=False)\n",
    "# embed2D = sio.loadmat('data1_random/std_data_run_0_cv_0_ng_500_pd_0-5_bs_1000_ld_2_ne_5000_ri_0-summaryUPDATE.mat', squeeze_me=True)\n",
    "\n",
    "df.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check file standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['pair', 'species', 'pre_class','post_class', 'pre_cre', 'post_cre',\n",
    "       'pre_layer', 'post_layer', 'pre_ex', 'post_ex', 'stp_induction_50hz']\n",
    "if not np.all([f in df.columns for f in features]):\n",
    "    for f in features:\n",
    "        if f not in df.columns:\n",
    "            print(\"missing\", f)\n",
    "    print('attempting to standarize data')\n",
    "    \n",
    "    #dealing with pair\n",
    "    if 'pair' in df.columns:\n",
    "        pass\n",
    "    elif 'pair_identifier' in df.columns:\n",
    "        df.rename(columns = {'pair_identifier':'pair'})\n",
    "    elif ('expt' in df.columns) & ('pre_cell' in df.columns) & ('post_cell' in df.columns):\n",
    "        pass\n",
    "    else:\n",
    "        raise Exceptation(\"cannot resolve missing 'pair' feature\") \n",
    "    \n",
    "    #dealing with class\n",
    "    if 'pre_class' not in df.columns:\n",
    "        if ('species' in df.columns) & ('pre_cre' in df.columns) & ('pre_layer' in df.columns):\n",
    "            df['pre_class']=df['pre_cre']\n",
    "            df['pre_class'].loc[df['species'] == 'human'] = 'human'\n",
    "            df['pre_class'].loc[(df['pre_cre'] == 'unknown') & (df['species'] == 'mouse') & (df['pre_layer'] == '2/3')] = '2/3'\n",
    "            df['pre_class'].loc[(df['pre_cre'] == 'unknown') & (df['species'] == 'mouse') & (df['pre_layer'] == '4')] = '4'\n",
    "            df['pre_class'].loc[(df['pre_cre'] == 'unknown') & (df['species'] == 'mouse') & (df['pre_layer'] == '6')] = '6'\n",
    "            df['pre_class'].loc[(df['pre_cre'] == 'unknown') & (df['species'] == 'mouse') & (df['pre_layer'] == '5')] = '5'\n",
    "        else:\n",
    "            raise Exceptation(\"cannot resolve missing 'pre_class' feature\") \n",
    "            \n",
    "    if 'post_class' not in df.columns:\n",
    "        if ('species' in df.columns) & ('post_cre' in df.columns) & ('post_layer' in df.columns):\n",
    "            df['post_class']=df['post_cre']\n",
    "            df['post_class'].loc[df['species'] == 'human'] = 'human'\n",
    "            df['post_class'].loc[(df['post_cre'] == 'unknown') & (df['species'] == 'mouse') & (df['post_layer'] == '2/3')] = '2/3'\n",
    "            df['post_class'].loc[(df['post_cre'] == 'unknown') & (df['species'] == 'mouse') & (df['post_layer'] == '4')] = '4'\n",
    "            df['post_class'].loc[(df['post_cre'] == 'unknown') & (df['species'] == 'mouse') & (df['post_layer'] == '6')] = '6'\n",
    "            df['post_class'].loc[(df['post_cre'] == 'unknown') & (df['species'] == 'mouse') & (df['post_layer'] == '5')] = '5'\n",
    "        else:\n",
    "            raise Exceptation(\"cannot resolve missing 'post_class' feature\") \n",
    "\n",
    "# remove actual data because not needed and takes up memory (actually maybe I do want it.)\n",
    "df.drop(df.columns.difference(features), 1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create pre-post nurmerical catagories for supervised learning tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Annotation combinations\n",
    "# df = df.assign(pre_post_class=(df['pre_class'].map(str) + '_' + df['post_class'].map(str)))\n",
    "# df = df.assign(pre_post_ex=(df['pre_ex'].map(str) + '_' + df['post_ex'].map(str)))\n",
    "\n",
    "# #Assign numeric id to 'combined_anno'\n",
    "# df = df.assign(num_pre_post_class=(df['pre_post_class']).astype('category').cat.codes)\n",
    "# df = df.assign(num_pre_post_ex=(df['pre_post_ex']).astype('category').cat.codes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create columns for the embedded data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#random embedding needs updates to work here\n",
    "\n",
    "# Note that you cannot run this cell twice because you will keep adding to dataframe\n",
    "if not (embed2D['zX'].shape[0] == df.shape[0]):\n",
    "    raise Exception('the dimensions of the embedding does not match the data')\n",
    "df = df.join(pd.DataFrame(embed2D['zX'], columns = ['embed2Da', 'embed2Db']))\n",
    "\n",
    "if 'embed3D' in locals(): #this is currently here because I don't have 3D embedding for random data yet\n",
    "    if not ((embed2D['zX'].shape[0] == df.shape[0]) & (embed3D['zX'].shape[0] == df.shape[0])):\n",
    "        raise Exception('the dimensions of the embedding does not match the data')\n",
    "    df = df.join(pd.DataFrame(embed3D['zX'], columns = ['embed3Da', 'embed3Db', 'embed3Dc' ]))\n",
    "else:\n",
    "    print('there is no 3D embedding')\n",
    "df.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed2D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SUPERVISED LEARNING: HOW WELL CAN PRE-SYNAPTIC EXICITATORY (E & I) CLASS BE DIFFERENTIATED IN THE LATENT SPACE?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### set up pre synaptic excitation DataFrame "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get rid of unknown excitation (this is annoying given that I will have to make a df for )\n",
    "df_pre_ex = df[df['pre_ex'] != 'U']\n",
    "\n",
    "#Assign numeric catatory for plotting\n",
    "df_pre_ex = df_pre_ex.assign(num_pre_ex=(df_pre_ex['pre_ex']).astype('category').cat.codes)\n",
    "\n",
    "# get a map of catagory codes for making legends (need to circle back)\n",
    "c = df_pre_ex.pre_ex.astype('category')\n",
    "d = dict(enumerate(c.cat.categories))\n",
    "print (d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### function for plotting and accuracy calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_and_classify(df, num_cat_name, embed_name_list):\n",
    "    ''' \n",
    "    plot the data in the pre_defined classification and assess how well those can be differentiated \n",
    "    in the latent space.\n",
    "    \n",
    "    input\n",
    "    -----\n",
    "    df: DataFrame\n",
    "    num_cat_name: string\n",
    "        specifies the name of the column with the numerical catagory\n",
    "    embed_name_list: list of strings\n",
    "        specifies the column names of the embedded space to be plotted\n",
    "    '''\n",
    "    # create embeded variable for ease\n",
    "    embed = df[embed_name_list].values\n",
    "    \n",
    "    # Train a Random Forrest on this to see how well it can be classified\n",
    "    y = df[num_cat_name].values\n",
    "    X_train, X_test, y_train, y_test = train_test_split(embed, y, stratify = y) #split up data based on equal number of y output\n",
    "    RF =  RandomForestClassifier(max_depth=None, min_samples_split=2).fit(X_train, y_train)\n",
    "    LR = LogisticRegression().fit(X_train, y_train)\n",
    "    yRF_predict = RF.predict(X_test)\n",
    "    yLR_predict = LR.predict(X_test)\n",
    "    print('RF accuracy', RF.score(X_test, y_test))\n",
    "    print('LR accuracy', LR.score(X_test, y_test))\n",
    "    print('naive accuracy', sum(y_test == 1)/len(y_test))\n",
    "    print('Random forrest confusion', metrics.confusion_matrix(y_test, yRF_predict))\n",
    "    print('Logistic regression confusion', metrics.confusion_matrix(y_test, yLR_predict))\n",
    "    \n",
    "    # make plot\n",
    "    # note: need to circle back to making a legend\n",
    "    #make 2D plot\n",
    "    if len(embed_name_list) == 2:\n",
    "        plt.figure(figsize = (15,15))\n",
    "        plt.scatter(embed[:,0], embed[:,1], s=1, c=df[num_cat_name].values, cmap='viridis')\n",
    "        ax = plt.gca()\n",
    "        ax.set_xlim(-4,4)\n",
    "        ax.set_ylim(-4,4)\n",
    "        \n",
    "    # make 3D plot\n",
    "    elif len(embed_name_list) == 3:\n",
    "        # Configure the trace.\n",
    "        trace = go.Scatter3d(\n",
    "        #    x=[1, 2, 3],  # <-- Put your data instead\n",
    "        #    y=[4, 5, 6],  # <-- Put your data instead\n",
    "        #    z=[7, 8, 9],  # <-- Put your data instead\n",
    "            x=embed[:,0], \n",
    "            y=embed[:,1],\n",
    "            z=embed[:,2],\n",
    "        #    s=1,\n",
    "            mode = 'markers',\n",
    "            marker = dict(\n",
    "                size = 5,\n",
    "                color=df[num_cat_name].values, \n",
    "                colorscale='viridis',\n",
    "                colorbar = dict()),\n",
    "        )\n",
    "\n",
    "        # Configure the layout.\n",
    "        layout = go.Layout(\n",
    "            margin={'l': 0, 'r': 0, 'b': 0, 't': 0}\n",
    "        )\n",
    "\n",
    "        data = [trace]\n",
    "        plot_figure = go.Figure(data=data, layout=layout)\n",
    "\n",
    "        # Render the plot.\n",
    "        plotly.offline.iplot(plot_figure)\n",
    "    else:\n",
    "        raise Exception('plotting dimension not defined')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2D embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_and_classify(df_pre_ex, 'num_pre_ex', ['embed2Da', 'embed2Db'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3D embedding does help a bit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_and_classify(df_pre_ex, 'num_pre_ex', ['embed3Da', 'embed3Db', 'embed3Dc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Look at post synaptic excitation instead"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### set up post synaptic excitation DataFrame "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get rid of unknown excitation (this is annoying given that I will have to make a df for )\n",
    "df_post_ex = df[df['post_ex'] != 'U']\n",
    "\n",
    "#Assign numeric catatory for plotting\n",
    "df_post_ex = df_post_ex.assign(num_post_ex=(df_post_ex['post_ex']).astype('category').cat.codes)\n",
    "\n",
    "# get a map of catagory codes for making legends (need to circle back)\n",
    "c = df_post_ex.pre_ex.astype('category')\n",
    "d = dict(enumerate(c.cat.categories))\n",
    "print (d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2D embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_and_classify(df_post_ex, 'num_post_ex', ['embed2Da', 'embed2Db'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3D embedding does help a bit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_and_classify(df_post_ex, 'num_post_ex', ['embed3Da', 'embed3Db', 'embed3Dc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Given that post synaptic excitation did classify much above chance it is unlikey that both together would help but let us check and take the opportunity to look at multiple catagories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### set up pre/post synaptic excitation DataFrame "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get rid of unknown excitation (this is annoying given that I will have to make a df for )\n",
    "df_pre_post_ex = df[~((df['pre_ex'] == 'U') | (df['post_ex'] == 'U'))]\n",
    "\n",
    "#Assign numeric catatory for plotting\n",
    "df_pre_post_ex = df_pre_post_ex.assign(pre_post_ex=(df_pre_post_ex['pre_ex'].map(str) + '_' + df_pre_post_ex['post_ex'].map(str)))\n",
    "df_pre_post_ex = df_pre_post_ex.assign(num_pre_post_ex=(df_pre_post_ex['pre_post_ex']).astype('category').cat.codes)\n",
    "\n",
    "# get a map of catagory codes for making legends (need to circle back)\n",
    "c = df_pre_post_ex.pre_post_ex.astype('category')\n",
    "d = dict(enumerate(c.cat.categories))\n",
    "print (d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2D embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_and_classify(df_pre_post_ex, 'num_pre_post_ex', ['embed2Da', 'embed2Db'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3D embedding does help a bit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_and_classify(df_pre_post_ex, 'num_pre_post_ex', ['embed3Da', 'embed3Db', 'embed3Dc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO\n",
    "* accuracy and baseline and for multiple catagories\n",
    "* how to differentiate which catagories are unhelpful i.e. have a lot of overlap (for example E2I and E2E largely the same?)  Might need to to a heirarchcal classification schema.\n",
    "    * perhaps quantify how well each individual class can be differentiated by every other individual class and combine non differentiable\n",
    "* variance of pair versus class\n",
    "* distribution of average amplitude, stp, cv accross this space\n",
    "* what are the outliers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SUPERVISED LEARNING: HOW WELL CAN CLASS BE DIFFERENTIATED IN THE LATENT SPACE? PRE_SYNAPTIC, POST_SYNAPTIC AND PAIR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First lets evalutate pre synaptic class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOOK AT DISTRIBUTION OF PARAMETERS ACCROSS THE SPACE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (15,15))\n",
    "plt.scatter(df['embed2Da'], df['embed2Db'], s=1, c=df['stp_induction_50hz'].values, cmap='viridis')\n",
    "plt.colorbar()\n",
    "ax = plt.gca()\n",
    "ax.set_xlim(-4,4)\n",
    "ax.set_ylim(-4,4)\n",
    "plt.title('STP Induction', fontsize=24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure the trace.\n",
    "trace = go.Scatter3d(\n",
    "#    x=[1, 2, 3],  # <-- Put your data instead\n",
    "#    y=[4, 5, 6],  # <-- Put your data instead\n",
    "#    z=[7, 8, 9],  # <-- Put your data instead\n",
    "    x=df['embed3Da'], \n",
    "    y=df['embed3Db'],\n",
    "    z=df['embed3Dc'],\n",
    "#    s=1,\n",
    "    mode = 'markers',\n",
    "    marker = dict(\n",
    "        size = 5,\n",
    "        color=df['stp_induction_50hz'].values, \n",
    "        colorscale ='viridis',\n",
    "        showscale = True)\n",
    ")\n",
    "\n",
    "# Configure the layout.\n",
    "layout = go.Layout(\n",
    "    margin={'l': 0, 'r': 0, 'b': 0, 't': 0}\n",
    ")\n",
    "\n",
    "data = [trace]\n",
    "plot_figure = go.Figure(data=data, layout=layout)\n",
    "\n",
    "# Render the plot.\n",
    "plotly.offline.iplot(plot_figure)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lets characterize variance of single pairs in the space.  Can we use the mean as a good descriptor of one pair?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make a new dataFrame where information is for one pair."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mean=df.groupby(features).mean()\n",
    "df_var=df.groupby(features).var()\n",
    "df_stat = pd.concat([df_mean, df_var],  axis=1)\n",
    "\n",
    "# -----------------BELOW IS DANGEROUS---------------\n",
    "# There used to be a way to specify subset in the concat but I can't find it therefore I am renaming the columns\n",
    "df_stat.columns = ['embed2Da_mean', 'embed2Db_mean', 'embed3Da_mean', 'embed3Db_mean',\n",
    "       'embed3Dc_mean', 'embed2Da_var', 'embed2Db_var', 'embed3Da_var',\n",
    "       'embed3Db_var', 'embed3Dc_var']\n",
    "\n",
    "# the multi-index does not appear to be working or be accessable as described.  I tried many different things.  \n",
    "# I couldnt even convert it to a numpy array and get the data out with indexing one would expect. So I am\n",
    "# hacking the info out via for loops\n",
    "anno_dict={}\n",
    "for name in df_stat.index.names:\n",
    "    anno_dict[name] = []\n",
    "\n",
    "for ii in range(len(df_stat.index)):\n",
    "    for n, name in enumerate(df_stat.index.names):\n",
    "        anno_dict[name].append(df_stat.index[ii][n])\n",
    "\n",
    "for key in anno_dict:\n",
    "    df_stat[key] = anno_dict[key]\n",
    "\n",
    "# remove the multi-index\n",
    "df_stat.reset_index(drop=True, inplace = True)\n",
    "\n",
    "# reorder columns for convenience\n",
    "cols = df_stat.columns.tolist()\n",
    "cols = cols[-len(features):] + cols[:-len(features)]\n",
    "df_stat = df_stat[cols]\n",
    "df_stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.errorbar(df_stat['embed2Da_mean'], \n",
    "             df_stat['embed2Db_mean'], xerr = df_stat['embed2Da_var'].values), \n",
    "   #          c=df_stat['stp_ind_50hz_mean'].values)\n",
    "#, cmap='viridis')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (15,15))\n",
    "plt.scatter(df_stat['embed2Da_mean'], \n",
    "             df_stat['embed2Db_mean'],  \n",
    "             c=df_stat['embed2Da_var'].values,\n",
    "             cmap='viridis')\n",
    "plt.colorbar()\n",
    "ax = plt.gca()\n",
    "ax.set_xlim(-4,4)\n",
    "ax.set_ylim(-4,4)\n",
    "plt.title('x_variance', fontsize=24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get rid of unknown excitation (this is annoying given that I will have to make a df for )\n",
    "df_pre_ex = df_stat[df_stat['pre_ex'] != 'U']\n",
    "\n",
    "#Assign numeric catatory for plotting\n",
    "df_pre_ex = df_pre_ex.assign(num_pre_ex=(df_pre_ex['pre_ex']).astype('category').cat.codes)\n",
    "\n",
    "# get a map of catagory codes for making legends (need to circle back)\n",
    "c = df_pre_ex.pre_ex.astype('category')\n",
    "d = dict(enumerate(c.cat.categories))\n",
    "print (d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pre_ex['pre_ex']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
